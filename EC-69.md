This project demonstrates how to query streaming data from Kafka using several Azure technologies:

Kafka Mirror Maker
Azure Event Hubs
Azure Stream Analytics
Azure Logic Apps
Service Now Integration
Workflow:

Generator App sents message to Kafka or Event Hubs
Stream Analytics will aggregate and filter messages into a second Event Hubs
Logic App will read events and create a ticket in Service Now





Today EC is reading from Kafka, but the reporting is all done via Azure Event Hub. This all needs to change to a new pattern that is not tightly coupled to Azure services, while also being mindful of the value this data has within the system. IT Ops needs to see these device events to ensure that work is being done before a device failure. ODS also need to make use of this data for reporting. 

MVP:

Replicate the logic that occurs in Event Hub into an AWS pattern to land SQL based insights into Service Now
Replace Apache NiFi to land device events/heartbeat data in current state as-is to ODS staging tables
Post go-live: Need to figure out what we're doing long term with the functionality that Solar Winds provides today



[OnPrem Kafka / Generator App] -> [MirrorMaker / MSK Replicator] -> [Amazon MSK (telemetry.raw, heartbeat.raw, alerts.raw)]
[Amazon MSK] -> [MSK Connect -> JDBC Sink -> ODS Staging (RDS/Aurora)]   // replaces NiFi (MVP)
[Amazon MSK] -> [Managed Flink (Flink SQL jobs)] -> [alerts.derived / telemetry.derived topics]
[alerts.derived] -> [Lambda (MSK consumer)] -> [ServiceNow REST API]
[Amazon MSK] -> [MSK Connect -> S3 raw lake]
[Observability] <- CloudWatch metrics, Prometheus (JMX exporter), Grafana
(Security): VPC-only access, TLS, SASL/IAM, KMS for at-rest encryption



Flow 1 — Replace Azure Stream path (paste into Lucidchart text-to-diagram)

(One-line: On-prem Kafka → replicate → MSK → Flink SQL → derived topics → Lambda → ServiceNow)

[Vending Machine / Generator App] -> [Event Collector (Edge Gateway)]
[Event Collector (Edge Gateway)] -> [On-Prem Kafka]
[On-Prem Kafka] -> [MirrorMaker / Replicator] -> [Amazon MSK (telemetry.raw, heartbeat.raw, alerts.raw)]
[Amazon MSK] -> [Managed Flink (Flink SQL Jobs) | consumes telemetry.raw, alerts.raw]
[Managed Flink (Flink SQL Jobs)] -> [alerts.derived, telemetry.derived topics (on MSK)]
[alerts.derived] -> [Lambda (MSK consumer / transformer)]
[Lambda (MSK consumer / transformer)] -> [ServiceNow REST API (create incident)]
[Amazon MSK] -> [MSK Connect -> S3 (raw archive)]
[Observability] <- CloudWatch Metrics, Prometheus (JMX exporter), Grafana
[Alerting] <- CloudWatch Alarms -> SNS Topic -> Lambda -> ServiceNow (Ops alerts)
(Security): VPC, TLS, SASL/IAM, KMS
(Notes): "Use partition by device-id/site-id for ordering; Flink handles ASA-like SQL transforms & windows"


Flow 2 — Replace NiFi landing to ODS staging (paste into Lucidchart text-to-diagram)

(One-line: MSK Connect JDBC Sink writes raw device/heartbeat events directly into ODS staging tables; S3 for archival)

[Device / Event Collector] -> [On-Prem Kafka]
[On-Prem Kafka] -> [MirrorMaker / Replicator] -> [Amazon MSK (telemetry.raw, heartbeat.raw)]
[Amazon MSK] -> [MSK Connect -> JDBC Sink -> ODS Staging (RDS / Aurora / External JDBC target)]
[Amazon MSK] -> [MSK Connect -> S3 (raw partitioned archive by date/device)]
[Optional] [Amazon MSK] -> [Consumer App / Batch ETL] -> [Transform -> Final ODS / Data Warehouse]
[Monitoring] <- CloudWatch Logs + Connector Metrics
[DLQ / Errors] -> [SQS or SNS] -> [Ops Lambda / Manual Review Workflow]
(Security): VPC, TLS, IAM, Secrets Manager for DB creds, KMS
(Notes): "MVP replaces NiFi with managed JDBC sink; retain NiFi in read-only mode for complex provenance if needed."

Compact Flow
-----------------------

External:
  Event Generator (Device) -> Kafka (Topics)
  Event Generator (Device) -> Azure Event Hubs (direct ingest)

Ingest:
  Kafka (Topics) -> Kafka MirrorMaker -> Event Hubs Namespace

Transform:
  Event Hubs Namespace -> Event Hub (aggregated stream)
  Event Hub -> Azure Stream Analytics -> Event Hub (filtered/output)

Notification:
  Event Hub -> Azure Logic Apps -> ServiceNow (create ticket)

Detailed Swimlanes
------------------------
Swimlane: External
  [Event Generator - Vending Machine] --AMQP / HTTPS / Kafka--> [Event Collector / Generator App]
  [Event Generator - Vending Machine] --kafka://tcp--> [Kafka Topics]

Swimlane: Ingest
  [Kafka Topics] --> [Kafka MirrorMaker]
  [Kafka MirrorMaker] --> [Event Hubs Namespace]
  [Event Generator] --(optional direct)--> [Azure Event Hubs] 

Swimlane: Transform
  [Event Hubs Namespace] --> [Event Hub 1]
  [Event Hubs Namespace] --> [Event Hub 2]
  [Event Hub N] --> [Azure Stream Analytics]
  [Azure Stream Analytics] --> [Event Hub (aggregated/filtered output)]

Swimlane: Notification
  [Event Hub (aggregated/filtered output)] --> [Azure Logic Apps]
  [Azure Logic Apps] --> [ServiceNow (now) : Create incident/ticket]

Notes:
  - Kafka holds multiple topics (Topic1, Topic2,... TopicN)
  - Stream Analytics aggregates & filters messages before output
  - Logic App reads from Event Hub and triggers ServiceNow integration



### Option -A
Event Generator -> Kafka
Kafka -> Kafka MirrorMaker
Kafka MirrorMaker -> Azure Event Hubs Namespace
Azure Event Hubs Namespace -> Event Hub (Raw Stream)
Event Hub (Raw Stream) -> Azure Stream Analytics
Azure Stream Analytics -> Event Hub (Filtered Output)
Event Hub (Filtered Output) -> Azure Logic Apps
Azure Logic Apps -> ServiceNow (Ticket Creation)


### option-B
[Event Generator] --> [Kafka]
[Event Generator] --> [Azure Event Hubs (direct)]
[Kafka] --> [Kafka MirrorMaker]
[Kafka MirrorMaker] --> [Event Hubs Namespace]
[Event Hubs Namespace] --> [Event Hub]
[Event Hub] --> [Azure Stream Analytics]
[Azure Stream Analytics] --> [Event Hub (Output)]
[Event Hub (Output)] --> [Azure Logic Apps]
[Azure Logic Apps] --> [ServiceNow]


### Option-C
flowchart LR
    EG(Event Generator) --> K(Kafka)
    EG --> EHDirect(Azure Event Hubs - Direct Ingest)
    K --> MM(Kafka MirrorMaker)
    MM --> EHNS(Event Hubs Namespace)
    EHNS --> EHRaw(Event Hub - Raw Messages)
    EHRaw --> ASA(Azure Stream Analytics)
    ASA --> EHOut(Event Hub - Filtered Output)
    EHOut --> LA(Azure Logic Apps)
    LA --> SN(ServiceNow)

